---
layout:     post
title:      浅谈移动平台创新玩法
date:       2016-12-04 17:16:49 +0800
author:     Zhang yinglong
tags: 	     杂文集
---

昨天有幸参加了ArchSummit北京2016全球架构师峰会，其中对阿里巴巴技术专家引商（花名）的《拥抱创新-聚划算无线团队创新玩法实践》感触颇多。索性也来谈谈移动平台创新玩法。

**什么是移动平台创新玩法**

2016年7月7日，由任天堂、Pokémon公司和谷歌Niantic Labs公司联合制作开发的手游《Pokémon GO》在澳大利亚新西兰区域首发，引爆了国内的新技术热潮，AR、VR、MR纷纷出现在公众视野。
**VR-Virtual Reality（虚拟现实）**，是利用电脑模拟产生一个三维空间的虚拟世界，提供使用者关于视觉、听觉、触觉等感官的模拟，让使用者如同身历其境一般，可以及时、没有限制地观察三度空间内的事物。
**AR-Augmented Reality（增强现实）**，指通过电脑技术将虚拟的信息应用到真实世界，真实的环境和虚拟的物体实时叠加到了同一个画面或空间。
**MR-Mixed Reality（混合现实）**，又称Hybrid Reality，将真实世界和虚拟世界混合在一起，来产生新的可视化环境，环境中同时包含了物理实体与虚拟信息，并且必须是实时的。
如何区分AR和MR呢？简单的区分办法是：虚拟物体的相对位置是否随设备的移动而移动，如果是，就是AR；如果不是，就是MR。
当然移动平台创新玩法远不止这些，人人都是产品设计师嘛。

**和AR有个约会**

今年9月份，产品经理跑过来问：我们能不能做一个AR相关的功能？于是开启了一段AR之路。首先要做的是技术选型，也就是技术领域的调研，笔者选型依据：
1、跨平台；
2、能快速接入，做出演示Demo；
3、免费。
因此和聚划算无线团队一样，选择了EasyAR。考虑快速出成果，没有使用其中的Unity 3D SDK。
![](/assets/images/2016/1200910-c04a3d32db063dc1.jpg)

**EasyAR的技术架构**，由于闭源笔者只能大致猜测一二。
![](/assets/images/2016/1200910-af883bfc82b09b97.jpg)

**Camera **- 摄像头负责图像二进制流数据的采集，跨平台封装了PC、iOS和Android的摄像头设备
**Player** - 视频播放器，可支持脱卡播放，目前不支持3D模型
**ImageTarget **- 配置识别目标图信息
**Frame** - 摄像头采集到二进制流数据帧数据处理，并通过OpenGL渲染至界面
**Barcode** - 二维码识别模块
**Recongnition** - 图像识别模块，这是EasyAR的核心部分，目前的版本只能本地识别本地图片，不支持云识别功能。支持云识别的2.0版本从10月底开始跳票，至今难产
**Tracker** - 图像跟踪模块

**为了支持“云识别”功能，笔者做了简单处理：把网络图片下载至本地加载，变相实现“云识别”功能。由于ImageTarget模块支持动态加载、卸载，在实际移动应用中也不太可能出现同时识别太多目标图片的需求，因此这是一种简易可行的方法。**
有兴趣的可以参见 https://github.com/zhangyinglong/ARKit 的效果。

**关于图像识别算法（相似图片搜索算法）**

首先来普及两个术语，**图像指纹和汉明距离**。图像指纹和人的指纹一样，是身份的象征，而**图像指纹简单点来讲，就是将图像按照一定的哈希算法，经过运算后得出的一组二进制数字**。**汉明距离**（计算机科班出身的应该都不陌生），**就是指从A变成B所经过的步骤数，这里指的是图像指纹的二进制数据变成另一组数据所需的步骤数**，显然，这个数值可以衡量两张图片的差异，汉明距离越小，则代表相似度越高。汉明距离为0，即代表两张图片完全一样。
笔者猜测EasyAR可能使用的是图像指纹算法，常见的有三种：

**平均哈希值（aHash）算法，是基于比较灰度图每个像素与平均值来实现的。**

步骤如下：
1.缩小图片：保留结构去掉细节，去除大小、横纵比的差异，把图片统一缩放到8*8，共64个像素的图片。
2.转化为灰度图：把缩放后的图片转化为256阶的灰度图。
附上灰度图相关算法（R = red， G = green， B = blue）
1).浮点算法：Gray=R*0.3+G*0.59+B*0.11
2).整数方法：Gray=(R*30+G*59+B*11)/100
3).移位方法：Gray =(R*76+G*151+B*28)>>8;
4).平均值法：Gray=（R+G+B）/3;
5).仅取绿色：Gray=G；
3.计算平均值： 计算进行灰度处理后图片的所有像素点的平均值。
4.比较像素灰度值：遍历灰度图片每一个像素，如果大于平均值记录为1，否则为0。
5.得到信息指纹：组合64个bit位，顺序随意保持一致性即可。
6.对比指纹：计算两幅图片的指纹，计算汉明距离（从一个指纹到另一个指纹需要变几次），汉明距离越大则说明图片越不一致，反之，汉明距离越小则说明图片越相似，当距离为0时，说明完全相同。（通常认为距离>10 就是两张完全不同的图片）。
平均哈希算法过于严格，不够精确，更适合搜索缩略图。

**感知哈希（pHash）算法，采用的是DCT（离散余弦变换）来降低频率的方法。**

步骤如下：
1.缩小图片：32 * 32是一个较好的大小，这样方便DCT计算。
2.转化为灰度图：把缩放后的图片转化为256阶的灰度图。（具体算法见平均哈希算法步骤）
3.计算DCT：DCT把图片分离成分率的集合
4.缩小DCT：DCT计算后的矩阵是32 * 32，保留左上角的8 * 8，这些代表的图片的最低频率
5.计算平均值：计算缩小DCT后的所有像素点的平均值。
6.进一步减小DCT：大于平均值记录为1，反之记录为0.
7.得到信息指纹：组合64个信息位，顺序随意保持一致性。
8.对比指纹。

**dHash算法**

步骤如下：
1.缩小图片：收缩到9*8的大小，以便它有72的像素点
2.转化为灰度图：把缩放后的图片转化为256阶的灰度图。（具体算法见平均哈希算法步骤）
3.计算差异值：dHash算法工作在相邻像素之间，这样每行9个像素之间产生了8个不同的差异，一共8行，则产生了64个差异值
4.获得指纹：如果左边的像素比右边的更亮，则记录为1，否则为0.最后比对两张图片的指纹，获得汉明距离即可。
相比pHash，dHash的速度要快的多，相比aHash，dHash在效率几乎相同的情况下的效果要更好，它是基于渐变实现的。

**基于OpenCV的图像识别算法**



此外，今年10月雅虎开源了一个基于深度学习的神经网络算法 - [色情图片检测](https://github.com/yahoo/open_nsfw)，有兴趣的朋友可以去研究一下，体验一下深度学习。

**云识别引擎**

这里就引用阿里巴巴PPT中的流程图来说明
![](/assets/images/2016/1200910-1a9b42a90bf296c4.jpg)

UI主线程在OpenGL渲染过程中，会不断地从当前帧数据中获取traker状态值，获取到表示目标已识别，否则表示目标未识别。当前已识别的会被标记为跟踪目标，若跟踪目标的traker状态值变为丢失时，则表示识别失败目标已丢失，主线程进入下一轮循环。即左部分的流程图，右部分的图表示图像识别的算法过程。
阿里巴巴集团作为中国互联网的龙头之一自然不会受制于任何第三方，于是开始搭建自己的云识别系统，说不定还会放到阿里云，开放云识别能力（EasyAR会不会感到亚历山大呢）。**所谓云识别，指的是无需将识别目标下载至本地，即可识别的技术。**
![](/assets/images/2016/1200910-2347a1f7909d61be.jpg)

![](/assets/images/2016/1200910-b9937a41c26235be.jpg)

![](/assets/images/2016/1200910-695237865c575513.jpg)

**新玩法畅想**

《Pokémon GO》基于LBS系统的玩法与电商APP结合，当用户走在路上发现某个人穿了一件很漂亮的衣服，掏出手机扫一扫立刻会显示出穿在路人身上衣服的所有信息，并智能引导用户去最近的商铺购买，推荐最新的优惠信息等。当然要是不用掏手机，而是像Google Glass那样的可穿戴智能设备体验更佳。
再比如，用户看到网上某件衣服很想买，但有担心看到的和实际的不一样，掏出手机扫一扫，立刻可以把识别出来的衣服像游戏装备一样穿在身上，体验试穿效果。总之脑洞打开。