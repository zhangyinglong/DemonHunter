---
layout:     post
title:      再谈AR中的图像识别算法
date:       2016-12-12 11:30:44 +0800
author:     Zhang yinglong
tags: 	    iOS
---

之前在《浅谈移动平台创新玩法》简单的猜测了easyar中使用的图像识别算法，基于图片指纹的哈希算法的图片检索 。后再阿里引商大神的指点下，意识到图片检测只适用于静态图片的识别，只能做AR脱卡（不进行图像追踪），简单地说就是如果图片有角度翻转，光线明暗的变化都会改变图片自身的指纹哈希值，无法做到跟踪识别。那要如何进行跟踪识别呢？

引商的指点：**我们用的是akaze，整个匹配流程采用的是基于特征提取加kmeans树求近似最近邻匹配的算法，然后再对匹配到的关键点对求单应性映射，最后根据inlier点集进行打分的方式来最终判定识别到的目标**。

#### 图像特征
和图像指纹类似，能够唯一标示，区别于其他图像的“有趣部分”。一个很抽象的概念，它的精确定义往往由具体问题或应用类型来决定。**可重复检测性**是图像特征最重要的特性：**同一图像无论发生角度，位移，明暗变化，所提取的特征应该是相同的**。图像特征是许多计算机图像分析算法的起点，因此一个算法是否成功往往由它使用和定义的特征决定。
常用的图像特征有颜色特征，纹理特征，形状特征，空间关系特征。
> 颜色特征，是一种全局特征，描述了图像或图像区域所对应景物的表面性质。例如灰度直方图等。
> 纹理特征，是一种全局特征，描述了图像或图像区域所对应景物的表面性质。例如基于共生矩阵的熵、角二阶矩和局部平稳性等。
>形状特征，是一种局部特征，描述了局部区域内物体的外形性质。例如边界特征等。
>空间关系特征，是指图像中分割出来的多个目标之间的相互的空间位置或相对方向关系。这些关系也可分为连接/邻接关系、交叠/重复关系和包含/包容关系等。

特征被检测后它可以从图像中被提取出来。这个过程可能需要许多图像处理的计算（如大名鼎鼎的计算机视觉图像处理库OpenCV）。其结果被称为特征描述或者特征向量。

#### AKAZE特征提取算法

KAZE是 Pablo F. Alcantarilla，Adrien Bartoli和Andrew J. Davison2012年在ECCV2012[ECCV是计算机视觉领域最顶尖的三个会议（CVPR、 ECCV， ICCV）之一，每两年一次]中提出来的一种比SIFT、SURF（OpenCV 2.4.9版本中实现的图像特征检测算法）更稳定、性能更好的特征检测算法。

KAZE特征检测是在图像域中进行非线性扩散处理的过程。KAZE算法的作者提出采用加性算子分裂算法(Additive Operator Splitting, AOS)来进行非线性扩散滤波，可以采用任意步长来构造稳定的非线性尺度空间。
AKAZE 是加速版KAZE特征，即Accelerated KAZE Features。作者基于OpenCV实现了Akaze算法的代码，在项目主页（http://www.robesafe.com/personal/pablo.alcantarilla/kaze.html）可以下载到完整的实现源代码，具体使用中可以下载OpenCV 3.0及以上版本直接调用Akaze算法类（http://docs.opencv.org/3.0-beta/doc/tutorials/features2d/akaze_matching/akaze_matching.html）。

#### K-Meas算法

在数据挖掘中，K-Means 算法是一种聚类分析的算法。**K-Means聚类的目的是：把n个点（可以是样本的一次观察或一个实例）划分到k个聚类中，使得每个点都属于离他最近的均值（此即聚类中心）对应的聚类，以之作为聚类的标准。**
K-Means算法主要解决的问题：我们可以看到，在图的左边有一些点，我们用肉眼可以看出来有四个点群，但是我们怎么通过计算机程序找出这几个点群来呢？于是就出现了我们的K-Means算法。
![K-Means算法.jpg](/assets/images/2016/1200910-407b622a2f7d4668.jpg)

例如在互联网金融公司的借贷业务中，给你1000000个用户，需要按金融产品种类分成n个人群，每一群人都有各自的“突出特征”（类似图像特征），以便区分出来他们都能适用哪一类产品，帮助金融公司合理规避借贷风险，这就是互联网金融公司基于大数据分析风控系统的基本原理。
这么解释K-Means算法是不是就容易理解多了。

#### 单应性

单应性是几何中的一个概念，是一个从实射影平面到射影平面的可逆变换，直线在该变换下仍映射为直线。具有相同意义的词还包括直射变换、射影变换和射影性等。在计算机视觉领域中，空间中同一平面的任意两幅图像可以通过单应性关联在一起。比如一个物体可以通过旋转相机镜头获取两张不同的照片（这两张照片的内容不一定要完全对应，部分对应即可），我们可以把单应性设为一个二维矩阵M，那么照片1乘以M就是照片2。这有着很多实际应用，比如图像校正、图像对齐或两幅图像之间的相机运动计算（旋转和平移）等。
在数学里齐次坐标，或投影坐标是指一个用于投影几何里的坐标系统，如同用于欧氏几何里的笛卡儿坐标一样。如果点Q到成像仪上的点q的映射使用齐次坐标，这种映射可以用矩阵相乘的方式表示。若有一下定义：
![](/assets/images/2016/1200910-e7150e5f136a8e80.png)

则可以将单应性简单的表示为：
![](/assets/images/2016/1200910-b108bcac0e5f35a4.png)

这里引入参数s，它是任意尺度的比例（目的是使得单应性定义到该尺度比例）。H有两部分组成：用于定位观察的物体平面的物理变换和使用摄像机内参数矩阵的投影。
![](/assets/images/2016/1200910-25e680951872fca4.png)

物理变换部分是与观测到的图像平面相关的部分旋转R和部分平移t的影响之和，表示如下：
![](/assets/images/2016/1200910-ed96592c3547881d.png)

这里R为3*3大小的矩阵，t表示一个3维的列矢量，摄像机内参数矩阵用M表示，那么我们重写单应性如下：
![](/assets/images/2016/1200910-26b9e6008fe7a51d.png)

单应性研究的是一个平面上到另外一个平面的映射，那么上述公式中的~Q，就可以简化为平面坐标中的~Q'，即我们使Z=0。即物体平面上的点我们用x,y表示，相机平面上的点，我们也是用二维点表示。我们去掉了Z方向的坐标，那么相对于旋转矩阵R，R可以分解为R=[r1 r2 r3]，那么r3也就不要了，参考下面的推导：
![](/assets/images/2016/1200910-72dfb11150d49897.png)
其中H为：
![](/assets/images/2016/1200910-c75d16afd5f65af5.png)
是一个3×3大小的矩阵，故最终的单应性矩阵可表示如下：
![](/assets/images/2016/1200910-2f4b162b71fe6e4f.png)
OpenCV就是利用上述公式来计算单应性矩阵。它使用同一物体的多个图像来计算每个视场的旋转和平移，同时也计算摄像机的内参数。

#### inlier点集验证

K-Means算法解决了图像特征聚类分析的问题，现在需要解决验证的问题 。OpenCV中有很多种匹配算法SIFT、ORB、RANSAC等算法，这里只说比较有名的RANSAC算法。RANSAC算法是一种简单且有效的去除噪声影响，估计模型的一种方法。与普通的去噪算法不同，RANSAC算法是使用尽可能少的点来估计模型参数，然后尽可能的扩大得到的模型参数的影响范围。 
RANSAC算法的具体描述是：给定N个数据点组成的集合P，假设集合中大多数的点都是可以通过一个模型来产生的，且最少通过n个点（n<N）可以拟合出模型的参数，则可以通过以下的迭代方式拟合该参数。 
对下面的操作执行k次： 
（1）从P中随机选择n个数据点； 
（2）用这n个数据点拟合出一个模型M； 
（3）对P中剩余的数据点，计算每个点与模型M的距离，距离超过阈值的则认定为局外点（及outlier点），不超过阈值的认定为局内点（及inlier点），并记录该模型M所对应的局内点的值m； 
迭代k次以后，选择m最大的模型M作为拟合的结果。 
因为在实际应用中N的值通常会很大，那么从其中任选n个数据点的组合就会很大，如果对所有组合都进行上面的操作运算量就会很大，因此对于k的选择就很重要。通常情况下，只要保证模型估计需要的n个点都是点的概率足够高即可。因此设w为N个数据中局内点的比例，z为进行k次选取后，至少有一次选取的n个点都是局内点的概率。则有
![](/assets/images/2016/1200910-13459cd8b9fc7207.png)
其中 1−wn 表示一次选取不都是局内点的概率，(1−wn)k 表示k次选取中没有一次都是局内点的概率。 则有：
![](/assets/images/2016/1200910-428b8c4fffcc20aa.png)
这里z一般要求满足大于95%即可。
至此一个完整的AR识别追踪流程原理分析完毕，后续就是OpenCV源码研究。
